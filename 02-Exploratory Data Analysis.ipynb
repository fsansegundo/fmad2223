{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c678edc",
   "metadata": {},
   "source": [
    "## <span style='background:yellow; color:red'> Remember:</span>\n",
    "\n",
    "+ Navigate to your `fmad2223` folder in the console  \n",
    "+ Execute `git pull origin main` to update the code\n",
    "+ **Do not modify the files in that folder**, copy them elsewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26924db1",
   "metadata": {},
   "source": [
    "# Working with Data Files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd8ca8",
   "metadata": {},
   "source": [
    "## Basic Data Files (txt, csv) with Pandas.\n",
    "\n",
    "+ We will begin by downloading one of these files, called `movies.csv` containing information about the top watched films (in theaters) between 2007 and 2011. \n",
    "\n",
    "+ We strongly recommend that you always create a project specific `data` folder and store all the downloaded data files for each project in there. In our case you can keep this folder as a subfolder of the *Course Folder*. In particular, do not place the files inside the *Common Repository folder* (the one named *fmad2223*). Use the following link to download the data file (it is advised to use the right button of your mouse and choose an option such as \"download the linked file as...\"):  \n",
    "    [movies.csv](https://gist.githubusercontent.com/tiangechen/b68782efa49a16edaf07dc2cdaa855ea/raw/0c794a9717f18b094eabab2cd6a6b9a226903577/movies.csv)\n",
    "\n",
    "+ Before proceeding to read the file with Python **you should always begin examining the contents of a data file with a text editor** (such as Notepad++ in Windows or BBedit in Mac). Not doing so will often result in bad data processing downstream. And please refrain from using spreadsheets (such as Excel) for this exploratory tasks. Not only will it fail too often, in some cases it can lead to data loss.  \n",
    "\n",
    "+ In this case opening the file in a text editor (BBedit in the Mac here) shows something like this (only the first few lines are shown):\n",
    "![](fig/010-movies_csv_open_text_editor.png)\n",
    "There are some key ingredients of such files that you need to pay attention to here, even in simple cases like this first example:\n",
    "    + Each line of the file corresponds to a row of the data table. \n",
    "    + The first line or *header* is often a special line, containing the names of the table columns. In the best case scenario these correspond to the variables in our data.\n",
    "    + The individual column values in every line are separated by a fixed symbol: a comma, a semicolon, a space or tab, etc. This will be called the *separator* and it is critical to determine which one was used in each data file. For movies.csv the separator is a comma.\n",
    "    \n",
    "+ Now that we have some information about the file we are ready to load it into a Pandas Dataframe, that we will also call `movies`. Note that we first need to import Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a0c5dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Film   Genre            Lead Studio  \\\n",
      "0                     Youth in Revolt  Comedy  The Weinstein Company   \n",
      "1  You Will Meet a Tall Dark Stranger  Comedy            Independent   \n",
      "2                        When in Rome  Comedy                 Disney   \n",
      "3               What Happens in Vegas  Comedy                    Fox   \n",
      "4                 Water For Elephants   Drama       20th Century Fox   \n",
      "\n",
      "   Audience score %  Profitability  Rotten Tomatoes % Worldwide Gross  Year  \n",
      "0                52       1.090000                 68         $19.62   2010  \n",
      "1                35       1.211818                 43         $26.66   2010  \n",
      "2                44       0.000000                 15         $43.04   2010  \n",
      "3                72       6.267647                 28        $219.37   2008  \n",
      "4                72       3.081421                 60        $117.09   2011  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_csv('data/movies.csv', sep=\",\", header=0)\n",
    "\n",
    "print(movies.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268801e8",
   "metadata": {},
   "source": [
    "+ The arguments `sep` and `header` provide the Pandas [read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) function with the information we discovered in our initial file exploration. If you run the function like this:\n",
    "\n",
    "    ```python\n",
    "    movies = pd.read_csv('data/movies.csv')\n",
    "    ```\n",
    "    Pandas will try to *guess* which separator to use and whether or not there is a header line. This `movies.csv` file is such an easy example that the code will work either way. But be warned: this will sometimes fail and when working with many large files the guessing adds an unnecessary overhead to the process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6528bdea",
   "metadata": {},
   "source": [
    "**Exercise:** \n",
    "\n",
    "+ using the commands we saw in `01a_test_your_setup` find out the shape (rows, columns) of this DataFrame.\n",
    "+ use the bracket selection (with `loc` or `iloc`) to get the `Genre` information for the movies from year 2010. What type of object did you obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "182b2a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Comedy\n",
       "1        Comedy\n",
       "2        Comedy\n",
       "8        Comedy\n",
       "20       Comedy\n",
       "21    Animation\n",
       "23       Comedy\n",
       "24       Comedy\n",
       "25       Comedy\n",
       "27        Drama\n",
       "32       Comedy\n",
       "48       Comedy\n",
       "49       Comedy\n",
       "51       Comedy\n",
       "52       Comedy\n",
       "54       Action\n",
       "55       Comedy\n",
       "58       Comedy\n",
       "62       Comedy\n",
       "70        Drama\n",
       "Name: Genre, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.loc[movies.Year == 2010, 'Genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c33d50d",
   "metadata": {},
   "source": [
    "### Reading the csv file from a URL (link)\n",
    "\n",
    "+ Sometimes it is simpler to skip the download part of the process and read the data directly from a link. Keep in mind, however, that for this to work the same caveats as before apply: it is better to explicitly set the separator, to know beforehand if there is a header in the file, etc.\n",
    "\n",
    "+ Let us see a classic example: the `mpg` data set can be downloaded [in csv format with this link](https://raw.githubusercontent.com/tidyverse/ggplot2/main/data-raw/mpg.csv). This data set contains information about fuel consumption (miles per gallon, thus mpg) and other characteristics of some car models from 1999 to 2008. You can read more aboout it and the variables it contains [in this link](https://ggplot2.tidyverse.org/reference/mpg.html).\n",
    "\n",
    "+ We use this example to show that we can use the link to the csv file as argument for Pandas `read_csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48949b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  manufacturer model  displ  year  cyl       trans drv  cty  hwy fl    class\n",
      "0         audi    a4    1.8  1999    4    auto(l5)   f   18   29  p  compact\n",
      "1         audi    a4    1.8  1999    4  manual(m5)   f   21   29  p  compact\n",
      "2         audi    a4    2.0  2008    4  manual(m6)   f   20   31  p  compact\n",
      "3         audi    a4    2.0  2008    4    auto(av)   f   21   30  p  compact\n",
      "4         audi    a4    2.8  1999    6    auto(l5)   f   16   26  p  compact\n"
     ]
    }
   ],
   "source": [
    "mpg_link = \"https://raw.githubusercontent.com/tidyverse/ggplot2/main/data-raw/mpg.csv\"\n",
    "mpg = pd.read_csv(mpg_link)\n",
    "\n",
    "print(mpg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19def427",
   "metadata": {},
   "source": [
    "### Creating and saving a csv file\n",
    "\n",
    "+ Next let us begin by creating a Pandas DataFrame with synthetic data. Learning to create such objects is an essential part of the data analysis skills required in this course. You will often need to simulate data with prescribed stratistical properties in order to perform computer experiments. These are in turn the key to understand the expected behavior in many real world problems. \n",
    "\n",
    "+ The NumPy and Scipy modules offer many tools for statistical modeling, and we will be meeting many of these tools in the next sessions. Here we begin with a simple example in which we use NumPy. You can [use this link](https://numpy.org/doc/1.16/reference/routines.random.html) to read the documentation for the functions we use and to get a first idea of the possibilities. For the time being it is ok if you don't fully understand some of the words below. We will discuss these issues later in the course:\n",
    "    + The `np.random.randint` function to generate 100 random integers between 1 and 20 (both included, of course with replacement). These become the Pandas Series `A`. Recall that each column of a Data.Frame is a Series.\n",
    "    + The `str.ascii_lowercase` string contains all the English alphabet lower case letters. We use a list comprehension to convert that to a NumPy array and then use `np.random.choice` to select 100 random letters with replacement. These form the Series `B`.\n",
    "    + Finally we use `np.random.random_sample` to obtain 100 random floating values uniformly distributed in the $[-4, 4]$ interval. These form the Series `C`.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99b8fc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A  B         C\n",
      "0  14  z -0.167330\n",
      "1  17  c  3.844925\n",
      "2  18  x -3.228774\n",
      "3  18  g -3.175198\n",
      "4  17  t  1.031381\n",
      "5  19  b  3.501944\n",
      "6  17  z  2.581804\n",
      "7  10  l  3.358491\n",
      "8   2  s -2.192685\n",
      "9  12  c  3.230474\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2022)  # seed for reproducibility\n",
    "\n",
    "# 100 random integers\n",
    "A = pd.Series(np.random.randint(low = 1, high = 21, size = 100))\n",
    "\n",
    "# 100 random lowercase letters\n",
    "import string as str\n",
    "alphabet_string = str.ascii_lowercase\n",
    "alphabet = np.array([alphabet_string[i] for i in range(len(alphabet_string))])\n",
    "B = pd.Series(np.random.choice(alphabet, size=100))\n",
    "\n",
    "# 100 random floats in [-4, 4]\n",
    "C = pd.Series(8 * np.random.random_sample(size=100) - 4)\n",
    "\n",
    "\n",
    "# Use the above as columns for a DataFrame\n",
    "X = pd.DataFrame({'A':A, 'B':B, 'C':C})\n",
    "print(X.head(n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c994423d",
   "metadata": {},
   "source": [
    "+ Now that we have created this DataFrame we can save it to a csv file. To identify it we will name that file `EDA_data_saving.csv` (in the `data` folder). Every Pandas DataFrame has a `to_csv` method that we can use for this. Run the following command and then use a text editor (Notepad++, BBEdit or similar) to check that the contents are what you expect. Make sure to check the header line, the separator and the number of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b1cc049",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"data/EDA_data_saving.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be997c",
   "metadata": {},
   "source": [
    "+ **Exercise:** change the separator to a comma and set `index = True`. Then run the code and check the changes. \n",
    "\n",
    "    In general we recommend setting `index=False` unless you have a good reason not to. These makes reading the csv files in other programs easier. Be careful because the default behavior is `index=True`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b1c503",
   "metadata": {},
   "source": [
    "## Excel Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7374b5c1",
   "metadata": {},
   "source": [
    "+ Excel files are frequently used as a data source in some contexts. For simple files, reading their content into a Pandas DataFrame is quite straightforward. But for more complex cases things can get more complicated. However, to keep things simple here we will use a simple file containing data about 2010 train accidents in the US. You can download the file (to the data folder) using [right-click in this link](http://users.stat.ufl.edu/~winner/data/train_acc_2010.xls). \n",
    "\n",
    "+ First we need to install an additional module into the fmad environment. This will often be the case when reading data from other sources. Do you remember how to install new modules?\n",
    "  **Exercise:** install the module called `xlrd` into the fmad environment.\n",
    "\n",
    "+ Then run this code to read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "85036b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Acident Railroad  Month  Day State      County TrkType TrkMnt AccType  \\\n",
      "0        1      NS       1    1   KY      KENTON    Main     NS     Der    \n",
      "1        2     ATK       1    2   CA     ALAMEDA    Yard    ATK     Oth    \n",
      "2        3    BNSF       1    2   MT      DAWSON    Yard   BNSF     Der    \n",
      "3        4    BNSF       1    2   OK       TULSA    Yard   BNSF     Der    \n",
      "4        5    MNCW       1    2   CT   FAIRFIELD    Main   MNCW     Oth    \n",
      "\n",
      "  AccCause  EqpDamg  TrkDamg  Killed  Injured           RREquip  Speed  \\\n",
      "0        T     8485   333700       0        0    FREIGHT TRAIN      24   \n",
      "1        M  1500000        0       0        0  PASSENGER TRAIN       0   \n",
      "2        H   103833    17615       0        0    FREIGHT TRAIN      10   \n",
      "3        M    15000    50000       0        0    LIGHT LOCO(S)       4   \n",
      "4        E     9964      750       0        0  PASSENGER TRAIN      45   \n",
      "\n",
      "   LocosDer  CarsDer  \n",
      "0         0       13  \n",
      "1         0        0  \n",
      "2         0        6  \n",
      "3         5        0  \n",
      "4         0        0  \n"
     ]
    }
   ],
   "source": [
    "xlsx_file = './data/train_acc_2010.xls'\n",
    "\n",
    "train_accidents = pd.read_excel(xlsx_file)\n",
    "\n",
    "print(train_accidents.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31de66a4",
   "metadata": {},
   "source": [
    "+ You can read the [documentation for the `read_excel` function here](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html). The examples therein will show you how to select a particular range of rows and columns in the spreadsheet and how to deal with the case when there are several sheets of data in the Excel file. And if you need to export directly from Python to Excel [read about the `to_excel` method here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9f2a8",
   "metadata": {},
   "source": [
    "# Different Types of Data\n",
    "\n",
    "+ The data sets we are beginning to see in these examples follow the two most basic rules of what is called *Tidy Data* (a term coined by Hadley Wickham in 2014):\n",
    "    + Each column of the table corresponds to a *variable*.\n",
    "    + Each row corresponds to an *observation*, *individual*, *case* or *sample*. All these terms refer to a single observational unit of whatever it is that we are considering.\n",
    "    \n",
    "+ The variables can be of different types: integer or floating point numbers, dates, binary variables (yes/no type), text strings, labels, dates, positions, etc. Those different types of variables allow for different operations and need specific treatment in many cases, if we are to get out of them as much information as possible. \n",
    "\n",
    "+ In the next sections we will meet the basic types of data (variables) and the best way to describe them. We will be using some of the examples that we have already seen and some others like the ones introduced here:\n",
    "\n",
    "    + The framingham data set contains health data from a heart disease study that took place in Framingham (UK). [This link contains the csv file URL](https://raw.githubusercontent.com/mbdfmad/fmad2122/main/data/framingham.csv) and you can [read more about the study and the variables in the table here](https://biolincc.nhlbi.nih.gov/media/teachingstudies/FHS_Teaching_Longitudinal_Data_Documentation.pdf?link_time=2019-08-26_14:42:24.487245).\n",
    "    + The `flights` data set contains information about flights that departed from New York in 2013. [This link contains the csv file URL](https://github.com/byuidatascience/data4python4ds/raw/master/data-raw/flights/flights.csv). You can read more about this data set [in this link](https://rdrr.io/cran/nycflights13/man/flights.html).\n",
    "    \n",
    "+ **Exercise:** using the URLs above directly (without downloading) load these data sets into two Pandas DataFrames called, respectively, `framingham` and `flights`.   **Warning:** Some of the cells below will not work until you complete these exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ce2117b",
   "metadata": {
    "tags": [
     "raises-exception",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# %load \"code/EDA_exercise_import_csv.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6ffb663f",
   "metadata": {
    "scrolled": true,
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'framingham' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mframingham\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(framingham\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(framingham\u001b[38;5;241m.\u001b[39mdescribe())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'framingham' is not defined"
     ]
    }
   ],
   "source": [
    "print(framingham.columns)\n",
    "print(framingham.head())\n",
    "print(framingham.describe())\n",
    "print(framingham.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76b98993",
   "metadata": {
    "scrolled": true,
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mflights\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(flights\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(flights\u001b[38;5;241m.\u001b[39mdescribe())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flights' is not defined"
     ]
    }
   ],
   "source": [
    "print(flights.columns)\n",
    "print(flights.head())\n",
    "print(flights.describe())\n",
    "print(flights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d9600",
   "metadata": {},
   "source": [
    "+ Let us pause here to think about the kind of data types in the examples we have seen. Many (but not all) of the variables / columns in the data tables fit into one of these categories:\n",
    "    + *Quantitative o Numeric variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fecfbaa",
   "metadata": {},
   "source": [
    "# Discrete (Quantitative) Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94b026",
   "metadata": {},
   "source": [
    "# Continuous (Quantitative) Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a8f75f",
   "metadata": {},
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51fb6bd",
   "metadata": {},
   "source": [
    "# Measures of Center and Spread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc858f",
   "metadata": {},
   "source": [
    "# Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c1c0b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bff6b2d9",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a4a554",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f11484af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e6905f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80c2cfcf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
